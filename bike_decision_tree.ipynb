{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4UZJ5TLSIKS"
      },
      "source": [
        "# Bike Sharing Dataset using Decision Tree Regressor\n",
        "\n",
        "+ Based on Bike Sharing dataset from [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/Bike+Sharing+Dataset)\n",
        "+ This notebook is based upon the hourly data file, i.e. hour.csv\n",
        "+ This notebook showcases regression using Decision Trees"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uO0MRIFaSIKY"
      },
      "source": [
        "### Problem Statement\n",
        "Given the Bike Sharing dataset with hourly level information of bikes along with weather and other attributes, model a system which can predict the bike count."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9yBYqTtYSIKZ"
      },
      "source": [
        "## Import required packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f464sUF-SIKa"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "\n",
        "# data manuipulation\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# modeling utilities\n",
        "import pydotplus \n",
        "from sklearn import tree\n",
        "from sklearn import metrics\n",
        "from sklearn import preprocessing\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "# plotting libraries\n",
        "import seaborn as sn\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sn\n",
        "\n",
        "\n",
        "sn.set_style('whitegrid')\n",
        "sn.set_context('talk')\n",
        "params = {'legend.fontsize': 'x-large',\n",
        "          'figure.figsize': (30, 10),\n",
        "          'axes.labelsize': 'x-large',\n",
        "          'axes.titlesize':'x-large',\n",
        "          'xtick.labelsize':'x-large',\n",
        "          'ytick.labelsize':'x-large'}\n",
        "\n",
        "plt.rcParams.update(params)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g7CwvmR3SIKc"
      },
      "source": [
        "## Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EmVOl5iJSIKc",
        "outputId": "c9650a1e-37b5-4301-a46b-745f94c6e5d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of dataset::(17379, 17)\n"
          ]
        }
      ],
      "source": [
        "hour_df = pd.read_csv('hour.csv')\n",
        "print(\"Shape of dataset::{}\".format(hour_df.shape))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGL0Sl6ySIKd"
      },
      "source": [
        "## Preprocessing\n",
        "+ Standarize column names\n",
        "+ Typecast attributes\n",
        "+ Encode Categoricals using One Hot Encoding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p3h_-oidSIKe"
      },
      "source": [
        "### Standarize Column Names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ttuljFeUSIKf"
      },
      "outputs": [],
      "source": [
        "hour_df.rename(columns={'instant':'rec_id',\n",
        "                        'dteday':'datetime',\n",
        "                        'holiday':'is_holiday',\n",
        "                        'workingday':'is_workingday',\n",
        "                        'weathersit':'weather_condition',\n",
        "                        'hum':'humidity',\n",
        "                        'mnth':'month',\n",
        "                        'cnt':'total_count',\n",
        "                        'hr':'hour',\n",
        "                        'yr':'year'},inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b57AfH-GSIKg"
      },
      "source": [
        "### Typecast Attributes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l4djX2KYSIKg"
      },
      "outputs": [],
      "source": [
        "# date time conversion\n",
        "hour_df['datetime'] = pd.to_datetime(hour_df.datetime)\n",
        "\n",
        "# categorical variables\n",
        "hour_df['season'] = hour_df.season.astype('category')\n",
        "hour_df['is_holiday'] = hour_df.is_holiday.astype('category')\n",
        "hour_df['weekday'] = hour_df.weekday.astype('category')\n",
        "hour_df['weather_condition'] = hour_df.weather_condition.astype('category')\n",
        "hour_df['is_workingday'] = hour_df.is_workingday.astype('category')\n",
        "hour_df['month'] = hour_df.month.astype('category')\n",
        "hour_df['year'] = hour_df.year.astype('category')\n",
        "hour_df['hour'] = hour_df.hour.astype('category')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ci9t_tjUSIKh"
      },
      "source": [
        "\n",
        "### Encode Categoricals (One Hot Encoding)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZODH8r01SIKh"
      },
      "outputs": [],
      "source": [
        "def fit_transform_ohe(df,col_name):\n",
        "    \"\"\"This function performs one hot encoding for the specified\n",
        "        column.\n",
        "\n",
        "    Args:\n",
        "        df(pandas.DataFrame): the data frame containing the mentioned column name\n",
        "        col_name: the column to be one hot encoded\n",
        "\n",
        "    Returns:\n",
        "        tuple: label_encoder, one_hot_encoder, transformed column as pandas Series\n",
        "\n",
        "    \"\"\"\n",
        "    # label encode the column\n",
        "    le = preprocessing.LabelEncoder()\n",
        "    le_labels = le.fit_transform(df[col_name])\n",
        "    df[col_name+'_label'] = le_labels\n",
        "    \n",
        "    # one hot encoding\n",
        "    ohe = preprocessing.OneHotEncoder()\n",
        "    feature_arr = ohe.fit_transform(df[[col_name+'_label']]).toarray()\n",
        "    feature_labels = [col_name+'_'+str(cls_label) for cls_label in le.classes_]\n",
        "    features_df = pd.DataFrame(feature_arr, columns=feature_labels)\n",
        "    \n",
        "    return le,ohe,features_df\n",
        "\n",
        "# given label encoder and one hot encoder objects, \n",
        "# encode attribute to ohe\n",
        "def transform_ohe(df,le,ohe,col_name):\n",
        "    \"\"\"This function performs one hot encoding for the specified\n",
        "        column using the specified encoder objects.\n",
        "\n",
        "    Args:\n",
        "        df(pandas.DataFrame): the data frame containing the mentioned column name\n",
        "        le(Label Encoder): the label encoder object used to fit label encoding\n",
        "        ohe(One Hot Encoder): the onen hot encoder object used to fit one hot encoding\n",
        "        col_name: the column to be one hot encoded\n",
        "\n",
        "    Returns:\n",
        "        tuple: transformed column as pandas Series\n",
        "\n",
        "    \"\"\"\n",
        "    # label encode\n",
        "    col_labels = le.transform(df[col_name])\n",
        "    df[col_name+'_label'] = col_labels\n",
        "    \n",
        "    # ohe \n",
        "    feature_arr = ohe.fit_transform(df[[col_name+'_label']]).toarray()\n",
        "    feature_labels = [col_name+'_'+str(cls_label) for cls_label in le.classes_]\n",
        "    features_df = pd.DataFrame(feature_arr, columns=feature_labels)\n",
        "    \n",
        "    return features_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ceJ2DLf2SIKi"
      },
      "source": [
        "## Train-Test Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pc0KhOozSIKi",
        "outputId": "6e2ef98b-8272-45ce-e93f-544e963aa913"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training set::(11643, 15)(11643, 2)\n",
            "Testing set::(5736, 15)\n"
          ]
        }
      ],
      "source": [
        "X, X_test, y, y_test = train_test_split(hour_df.iloc[:,0:-3], hour_df.iloc[:,-1], \n",
        "                                                    test_size=0.33, random_state=42)\n",
        "\n",
        "X.reset_index(inplace=True)\n",
        "y = y.reset_index()\n",
        "\n",
        "X_test.reset_index(inplace=True)\n",
        "y_test = y_test.reset_index()\n",
        "\n",
        "print(\"Training set::{}{}\".format(X.shape,y.shape))\n",
        "print(\"Testing set::{}\".format(X_test.shape))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n6BORuSiSIKj"
      },
      "outputs": [],
      "source": [
        "cat_attr_list = ['season','is_holiday',\n",
        "                 'weather_condition','is_workingday',\n",
        "                 'hour','weekday','month','year']\n",
        "numeric_feature_cols = ['temp','humidity','windspeed','hour','weekday','month','year']\n",
        "subset_cat_features =  ['season','is_holiday','weather_condition','is_workingday']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bs_p_ht9SIKj"
      },
      "outputs": [],
      "source": [
        "encoded_attr_list = []\n",
        "for col in cat_attr_list:\n",
        "    return_obj = fit_transform_ohe(X,col)\n",
        "    encoded_attr_list.append({'label_enc':return_obj[0],\n",
        "                              'ohe_enc':return_obj[1],\n",
        "                              'feature_df':return_obj[2],\n",
        "                              'col_name':col})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hFZOO9sWSIKk",
        "outputId": "553e5b96-a125-4f60-e4f0-dc763024c9e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape::(11643, 19)\n"
          ]
        }
      ],
      "source": [
        "feature_df_list = [X[numeric_feature_cols]]\n",
        "feature_df_list.extend([enc['feature_df'] \\\n",
        "                        for enc in encoded_attr_list \\\n",
        "                        if enc['col_name'] in subset_cat_features])\n",
        "\n",
        "train_df_new = pd.concat(feature_df_list, axis=1)\n",
        "print(\"Shape::{}\".format(train_df_new.shape))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qc3nxDTQSIKk"
      },
      "source": [
        "## Decision Tree based Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8rtPRKzgSIKk"
      },
      "outputs": [],
      "source": [
        "X = train_df_new\n",
        "y= y.total_count.values.reshape(-1,1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GPt1qtXMSIKl",
        "outputId": "5819ff19-ba6e-4238-f991-598317272276"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((11643, 19), (11643, 1))"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X.shape,y.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50AnkwgRSIKl"
      },
      "source": [
        "## Sample Decision Tree Regressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YWo9hSRPSIKl",
        "outputId": "c74ae6aa-0fd6-4255-cf86-158170425e6e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DecisionTreeRegressor(max_depth=4, max_leaf_nodes=10, min_samples_split=5)"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dtr = DecisionTreeRegressor(max_depth=4,\n",
        "                            min_samples_split=5,\n",
        "                            max_leaf_nodes=10)\n",
        "dtr.fit(X,y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ndIqP3iSIKl",
        "outputId": "1101d125-c567-43f2-df1f-cebcba172cb1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.5645919317952333"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dtr.score(X,y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93ysrE3mSIKm"
      },
      "source": [
        "### Plot the Learnt Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IUCCd5uKSIKm",
        "outputId": "51c44490-6802-461c-fc16-24e3dbeb39c4"
      },
      "outputs": [
        {
          "ename": "InvocationException",
          "evalue": "GraphViz's executables not found",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mInvocationException\u001b[0m                       Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-14-ba598309297f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mdot_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexport_graphviz\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout_file\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mgraph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpydotplus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph_from_dot_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdot_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite_pdf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"bikeshare.pdf\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pydotplus\\graphviz.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(path, f, prog)\u001b[0m\n\u001b[0;32m   1808\u001b[0m                 \u001b[1;32mlambda\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1809\u001b[0m                 \u001b[0mf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfrmt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1810\u001b[1;33m                 \u001b[0mprog\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprog\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprog\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprog\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1811\u001b[0m             )\n\u001b[0;32m   1812\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pydotplus\\graphviz.py\u001b[0m in \u001b[0;36mwrite\u001b[1;34m(self, path, prog, format)\u001b[0m\n\u001b[0;32m   1916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1917\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1918\u001b[1;33m                 \u001b[0mfobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1919\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1920\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pydotplus\\graphviz.py\u001b[0m in \u001b[0;36mcreate\u001b[1;34m(self, prog, format)\u001b[0m\n\u001b[0;32m   1958\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprogs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1959\u001b[0m                 raise InvocationException(\n\u001b[1;32m-> 1960\u001b[1;33m                     'GraphViz\\'s executables not found')\n\u001b[0m\u001b[0;32m   1961\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1962\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mprog\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprogs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mInvocationException\u001b[0m: GraphViz's executables not found"
          ]
        }
      ],
      "source": [
        "dot_data = tree.export_graphviz(dtr, out_file=None) \n",
        "graph = pydotplus.graph_from_dot_data(dot_data) \n",
        "graph.write_pdf(\"bikeshare.pdf\") "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8haYm3OKSIKm"
      },
      "source": [
        "### Grid Search With Cross Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tR2Z-L9QSIKm"
      },
      "outputs": [],
      "source": [
        "param_grid = {\"criterion\": [\"mse\", \"mae\"],\n",
        "              \"min_samples_split\": [10, 20, 40],\n",
        "              \"max_depth\": [2, 6, 8],\n",
        "              \"min_samples_leaf\": [20, 40, 100],\n",
        "              \"max_leaf_nodes\": [5, 20, 100, 500, 800],\n",
        "              }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-FCREJiCSIKm"
      },
      "outputs": [],
      "source": [
        "grid_cv_dtr = GridSearchCV(dtr, param_grid, cv=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R8whi0oGSIKn"
      },
      "outputs": [],
      "source": [
        "grid_cv_dtr.fit(X,y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YU4B9qxSSIKn"
      },
      "source": [
        "### Cross Validation: Best Model Details"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cmrGEyqWSIKn"
      },
      "outputs": [],
      "source": [
        "print(\"R-Squared::{}\".format(grid_cv_dtr.best_score_))\n",
        "print(\"Best Hyperparameters::\\n{}\".format(grid_cv_dtr.best_params_))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "DIb9egDVSIKn"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame(data=grid_cv_dtr.cv_results_)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h48yxzvSSIKn"
      },
      "outputs": [],
      "source": [
        "fig,ax = plt.subplots()\n",
        "sn.pointplot(data=df[['mean_test_score',\n",
        "                           'param_max_leaf_nodes',\n",
        "                           'param_max_depth']],\n",
        "             y='mean_test_score',x='param_max_depth',\n",
        "             hue='param_max_leaf_nodes',ax=ax)\n",
        "ax.set(title=\"Effect of Depth and Leaf Nodes on Model Performance\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mn_k1Mo8SIKo"
      },
      "source": [
        "### Residual Plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "drXYXDckSIKo"
      },
      "outputs": [],
      "source": [
        "predicted = grid_cv_dtr.best_estimator_.predict(X)\n",
        "residuals = y.flatten()-predicted"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fimy82X-SIKo"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots()\n",
        "ax.scatter(y.flatten(), residuals)\n",
        "ax.axhline(lw=2,color='black')\n",
        "ax.set_xlabel('Observed')\n",
        "ax.set_ylabel('Residual')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gOATK5ENSIKo"
      },
      "outputs": [],
      "source": [
        "r2_scores = cross_val_score(grid_cv_dtr.best_estimator_, X, y, cv=10)\n",
        "mse_scores = cross_val_score(grid_cv_dtr.best_estimator_, X, y, cv=10,scoring='neg_mean_squared_error')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-FktHA-FSIKo"
      },
      "outputs": [],
      "source": [
        "print(\"avg R-squared::{}\".format(np.mean(r2_scores)))\n",
        "print(\"MSE::{}\".format(np.mean(mse_scores)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TcdQWYJ3SIKp"
      },
      "source": [
        "### Setting the model for Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N_GzFoLnSIKp"
      },
      "outputs": [],
      "source": [
        "best_dtr_model = grid_cv_dtr.best_estimator_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQOQSv0-SIKp"
      },
      "source": [
        "## Test Dataset Performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nh69ExIiSIKp"
      },
      "outputs": [],
      "source": [
        "test_encoded_attr_list = []\n",
        "for enc in encoded_attr_list:\n",
        "    col_name = enc['col_name']\n",
        "    le = enc['label_enc']\n",
        "    ohe = enc['ohe_enc']\n",
        "    test_encoded_attr_list.append({'feature_df':transform_ohe(X_test,le,ohe,col_name),\n",
        "                                   'col_name':col_name})\n",
        "    \n",
        "    \n",
        "test_feature_df_list = [X_test[numeric_feature_cols]]\n",
        "test_feature_df_list.extend([enc['feature_df'] for enc in test_encoded_attr_list if enc['col_name'] in subset_cat_features])\n",
        "\n",
        "test_df_new = pd.concat(test_feature_df_list, axis=1) \n",
        "print(\"Shape::{}\".format(test_df_new.shape))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B9givhzWSIKp"
      },
      "outputs": [],
      "source": [
        "X_test = test_df_new\n",
        "y_test = y_test.total_count.values.reshape(-1,1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "no7SGMyNSIKp"
      },
      "outputs": [],
      "source": [
        "y_pred = best_dtr_model.predict(X_test)\n",
        "residuals = y_test.flatten() - y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AcXR7QIsSIKq"
      },
      "outputs": [],
      "source": [
        "r2_score = best_dtr_model.score(X_test,y_test)\n",
        "print(\"R-squared::{}\".format(r2_score))\n",
        "print(\"MSE: %.2f\"\n",
        "      % metrics.mean_squared_error(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kye1OSciSIKq"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots()\n",
        "ax.scatter(y_test.flatten(), residuals)\n",
        "ax.axhline(lw=2,color='black')\n",
        "ax.set_xlabel('Observed')\n",
        "ax.set_ylabel('Residual')\n",
        "plt.show()\n",
        "\n",
        "r2_score = grid_cv_dtr.best_estimator_.score(X_test,y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0s9aoT3KSIKq"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gj8oZsYRSIKq"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}